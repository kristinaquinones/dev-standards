# User Research & Discovery

## Overview

User research and discovery help product teams understand user needs, validate assumptions, and make informed decisions. This section covers frameworks and methods for effective discovery work.

## Jobs-to-Be-Done (JTBD) Framework

### Core Principles

Jobs-to-Be-Done focuses on understanding the "job" users are trying to accomplish, not just the features they request.

**Key Concepts:**
- **Functional Job**: The practical task users need to complete
- **Emotional Job**: How users want to feel
- **Social Job**: How users want to be perceived by others
- **Context**: The situation in which the job occurs

### JTBD Process

1. **Identify the Job**: What job are users hiring your product to do?
2. **Understand the Context**: When, where, and why does this job occur?
3. **Map the Journey**: What steps do users take to complete the job?
4. **Identify Pain Points**: Where do users struggle or experience friction?
5. **Discover Opportunities**: Where can we create value?

### JTBD Interview Questions

- "Tell me about the last time you [did the job]"
- "What were you trying to accomplish?"
- "What was going on in your life that made you need to do this?"
- "What alternatives did you consider?"
- "What would have to happen for you to switch to a different solution?"

## Design thinking decision frameworks

### Design Thinking Principles

Design Thinking provides a human-centered approach to problem-solving:

1. **Empathize**: Understand users' needs and experiences
2. **Define**: Clearly articulate the problem to solve
3. **Ideate**: Generate a wide range of possible solutions
4. **Prototype**: Create low-fidelity versions to test ideas
5. **Test**: Validate solutions with real users

### Decision Frameworks

**How Might We (HMW) Questions:**
- Reframe problems as opportunities
- Format: "How might we [action] for [user] so that [outcome]?"
- Example: "How might we help busy parents plan meals so that they save time and reduce stress?"

**Problem Framing:**
- Start with user needs, not solutions
- Use "What if..." to explore possibilities
- Consider constraints and opportunities

**Solution Evaluation:**
- Desirability: Do users want this?
- Feasibility: Can we build this?
- Viability: Does this make business sense?

**Validating Design Thinking Insights:**

Design thinking generates hypotheses about user needs. Validate these with data: use user research to understand the problem, then experiments to test solutions before committing to build.

## Research methods

### Qualitative Methods

**User Interviews:**
- One-on-one conversations to understand motivations and behaviors
- Best for: Deep understanding, exploring new areas, building empathy
- Tips: Ask open-ended questions, listen more than you talk, probe for "why"

**Contextual Inquiry:**
- Observe users in their natural environment
- Best for: Understanding real-world usage, identifying workarounds
- Tips: Watch first, ask questions second, note environmental factors

**Focus Groups:**
- Group discussions to explore topics
- Best for: Generating ideas, understanding group dynamics
- Limitations: Groupthink, dominant voices, artificial setting

**Usability Testing:**
- Observe users interacting with prototypes or products
- Best for: Identifying usability issues, validating designs
- Tips: Give realistic tasks, observe without leading, ask follow-up questions

### Quantitative Methods

**Surveys:**
- Structured questions to gather data from many users
- Best for: Validating hypotheses, gathering preferences, measuring satisfaction
- Tips: Keep surveys short, use clear language, avoid leading questions

**Analytics:**
- Behavioral data from product usage
- Best for: Understanding what users do, identifying patterns
- Limitations: Doesn't explain "why" users behave certain ways

**A/B Testing:**
- Compare variations to measure impact
- Best for: Validating specific hypotheses, optimizing features
- Requires: Sufficient traffic, clear success metrics

### Mixed Methods

**Research Synthesis:**
- Combine qualitative insights with quantitative data
- Use qualitative to explain quantitative patterns
- Use quantitative to validate qualitative findings
- Create a complete picture of user needs and behaviors

## Research planning

### When to Do Research

- **Discovery**: Before building, to understand needs
- **Validation**: During development, to test assumptions
- **Evaluation**: After launch, to measure impact
- **Continuous**: Ongoing, to stay connected to users

### Research Questions

Before starting research, define:
- What do we need to learn?
- Who do we need to learn from?
- What decisions will this research inform?
- What methods will best answer our questions?

## Analysis & Synthesis

### Making Sense of Research

1. **Organize Findings**: Group related insights
2. **Identify Patterns**: Look for common themes
3. **Prioritize Insights**: Focus on what matters most
4. **Create Artifacts**: Personas, journey maps, opportunity maps
5. **Share Findings**: Make insights accessible to the team

### Research Artifacts

- **User Personas**: Representative user profiles
- **Journey Maps**: Visual representation of user experience
- **Pain Point Analysis**: Prioritized list of user frustrations
- **Opportunity Maps**: Areas where we can create value
- **Research Reports**: Summary of findings and recommendations

## Best practices

- **Start with Questions, Not Solutions**: Research to understand, not to validate preconceived ideas
- **Talk to Real Users**: Avoid assumptions and second-hand information
- **Mix Methods**: Combine qualitative and quantitative approaches
- **Use Research Data to Drive Decisions**: Use research data to validate design thinking insights - don't rely on intuition alone. For example, if design thinking suggests users want a certain feature, use quantitative research or experiments to validate demand before building
- **Share Widely**: Make research findings accessible to the whole team
- **Act on Insights**: Use research to inform decisions, not just to document

## From research to decision

### Using Research to Inform Decisions

Use research to inform hypotheses, then validate with experiments. Example flow: User interviews suggest users struggle with X → Form hypothesis 'Feature Y will solve problem X' → Design experiment to test hypothesis → Measure impact → Make decision based on data.

**Research-Informed Experiment Design:**

User research should inform experiment design. For example, if user interviews reveal that users struggle with a specific task, use that insight to design an experiment that measures whether a proposed solution actually improves task completion. The research helps you understand the problem, and the experiment validates whether your solution works.

## Related topics

- [Product & Design Process](product-design-process.md) - Using research to define features and design solutions
- [Prioritization Frameworks](prioritization-frameworks.md) - Using research insights for prioritization
- [Metrics & Success Criteria](metrics-success-criteria.md) - Measuring research impact
- [A/B Testing & Experimentation](../../measurement-docs/ab-testing-experimentation.md) - Validating research insights with experiments

